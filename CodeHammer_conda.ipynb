{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd871291-1d41-4ab1-8881-cc941f3c9012",
   "metadata": {},
   "source": [
    "November 1 , 2023\n",
    "\n",
    "Running this example on my brand spanking new 4090!\n",
    "\n",
    "[How to Load LLama 13b for Inference on a single RTX 4090](https://codehammer.io/how-to-load-llama-13b-for-inference-on-a-single-rtx-4090/)\n",
    "\n",
    "And no, this notebook is NOT part of the repo ...\n",
    "\n",
    "[Natural Language Processing with Transformers by Lewis Tunstall, Leandro von Werra, Thomas Wolf.](https://github.com/nlp-with-transformers/notebooks)\n",
    "\n",
    "conda activate /home/rob/Data3/hfpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f87d6ab-e1f6-410f-b1cc-8edb1e19b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b33dc1-7ff9-47bc-9c7e-8459ee05f6cb",
   "metadata": {},
   "source": [
    "All of these models load to the 4090 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516b0911-d38b-4ce3-8eb9-44e3e45e9fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bab20be75c94dd98d97b7ca2997fd8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.72 s, sys: 6.81 s, total: 14.5 s\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "checkpoint = 'meta-llama/Llama-2-7b'    # Nope!\n",
    "checkpoint = 'meta-llama/Llama-2-7b-hf' # Works! 7718MiB\n",
    "\n",
    "checkpoint = 'meta-llama/Llama-2-7b-chat'    #Nope! \n",
    "checkpoint = 'meta-llama/Llama-2-7b-chat-hf' # Works! 7718MiB\n",
    "\n",
    "checkpoint = 'meta-llama/Llama-2-13b'     # Nope!\n",
    "checkpoint = 'meta-llama/Llama-2-13b-hf'  # Works! 14006MiB\n",
    "\n",
    "checkpoint = 'meta-llama/Llama-2-13b-chat' # Nope!\n",
    "checkpoint = 'meta-llama/Llama-2-13b-chat-hf' #Works! 14006MiB\n",
    "\n",
    "\n",
    "# Last one wins, right?!\n",
    "checkpoint = 'meta-llama/Llama-2-13b-hf'\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint, load_in_8bit=True)\n",
    "\n",
    "# CPU times: user 1min 29s, sys: 1min 52s, total: 3min 21s\n",
    "# Wall time: 6h 16min 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9282ba-b39a-45dd-b7fd-c929949ff4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c48297295c49efbbf18cd85719dd56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1cc681341c41c1869cdac3517d8eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2adf46e632244ec8b35220b141a47c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4c815006984188b0f7cc6455e2c624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d84c004c-5e0f-4670-861b-874ec89f0ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "            task=\"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            max_new_tokens=64,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9db0d2a5-78af-40d1-8adc-7ee0b6f5a40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Question: What is the difference between a car and a truck?\\nAnswer: 1. A car is a 4 wheeled vehicle. 2. A truck is a 2 wheeled vehicle. 3. A car has 4 wheels. 4. A truck has 2 wheels. 5. A car is a 4 wheeled vehicle'}]\n"
     ]
    }
   ],
   "source": [
    "print(pipe(\"Question: What is the difference between a car and a truck?\\nAnswer: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ecc1a5c-9492-4211-9f7d-7a44446e05b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "            task=\"text-generation\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            max_new_tokens=256,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba6b42d-c4ce-44de-91c9-2933e4734efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Question: What is the difference between a car and a truck?\\nAnswer: 240\\nQuestion: What is the difference between a car and a motorcycle?\\nAnswer: 20\\nQuestion: What is the difference between a motorcycle and a truck?\\nAnswer: 360\\nQuestion: What is the difference between a truck and a train?\\nAnswer: 270\\nQuestion: What is the difference between a train and a plane?\\nAnswer: 115\\nQuestion: What is the difference between a plane and a helicopter?\\nAnswer: 280\\nQuestion: What is the difference between a helicopter and a submarine?\\nAnswer: 280\\nQuestion: What is the difference between a submarine and a whale?\\nAnswer: 25\\nQuestion: What is the difference between a whale and a shark?\\nAnswer: 35\\nQuestion: What is the difference between a shark and a bacteria?\\nAnswer: 340\\nQuestion: What is the difference between a bacteria and a virus?\\nAnswer: 230\\nQuestion: What is the difference between a virus and a virus particle?\\nAnswer: 10\\nQuestion: What is the difference'}]\n"
     ]
    }
   ],
   "source": [
    "print(pipe(\"Question: What is the difference between a car and a truck?\\nAnswer: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd378a-283f-4e46-a189-5ec77b17f24a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
